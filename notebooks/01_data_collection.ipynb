{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1: Data Collection - Turkish Financial Data\n",
        "\n",
        "## üìã Setup Instructions\n",
        "\n",
        "### Before You Start:\n",
        "1. **Get CBRT EVDS API Key** (for macroeconomic data):\n",
        "   - Visit: https://evds2.tcmb.gov.tr/\n",
        "   - Register for free account\n",
        "   - Get API key from your profile\n",
        "   - See `CBRT_API_SETUP.md` for detailed instructions\n",
        "\n",
        "2. **Optional: Use .env file** (recommended for security):\n",
        "   - Copy `.env.example` to `.env`\n",
        "   - Add your API key: `EVDS_API_KEY=your_key_here`\n",
        "   - The notebook will automatically load it\n",
        "\n",
        "### What This Notebook Does:\n",
        "- ‚úÖ Collects macroeconomic data from CBRT (inflation, interest rates, exchange rates)\n",
        "- ‚úÖ Collects BIST stock prices from Yahoo Finance\n",
        "- ‚úÖ Combines datasets for comprehensive analysis\n",
        "- ‚úÖ Saves all data to `data/raw/` folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1: Data Collection\n",
        "\n",
        "## Goal\n",
        "Collect Turkish financial datasets from various sources:\n",
        "1. Financial Ratios Dataset for BIST Manufacturing Firms (Zenodo)\n",
        "2. T√úƒ∞K financial statistics\n",
        "3. BIST stock data (if accessible)\n",
        "\n",
        "## Tasks\n",
        "- Download datasets\n",
        "- Load into pandas DataFrames\n",
        "- Initial data inspection\n",
        "- Save raw data to `../data/raw/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: C:\\Users\\cihan\\turkish_finance_ml\n",
            "Raw data directory: C:\\Users\\cihan\\turkish_finance_ml\\data\\raw\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.append(str(project_root / \"src\"))\n",
        "\n",
        "# Set up paths\n",
        "data_raw_dir = project_root / \"data\" / \"raw\"\n",
        "data_raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Raw data directory: {data_raw_dir}\")\n",
        "\n",
        "# Import our data collector\n",
        "from data_collection import TurkishFinancialDataCollector, get_evds_api_key_instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Test Your API Key (Optional)\n",
        "\n",
        "Run this cell to test if your API key works before collecting full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick API key test (run this after setting EVDS_API_KEY below)\n",
        "# Uncomment and run to test your key:\n",
        "# from test_api_key import test_api_key\n",
        "# test_api_key(EVDS_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 1: CBRT EVDS - Macroeconomic Data (RECOMMENDED) ‚≠ê\n",
        "\n",
        "**Source:** Central Bank of Turkey (CBRT) EVDS API\n",
        "\n",
        "**What you'll get:**\n",
        "- Consumer Price Index (CPI/T√úFE) - Inflation\n",
        "- Producer Price Index (PPI/√úFE)\n",
        "- Policy Interest Rates\n",
        "- USD/TRY Exchange Rates\n",
        "- Time-series format (monthly data from 2000+)\n",
        "\n",
        "**Steps:**\n",
        "1. Get API key from: https://evds2.tcmb.gov.tr/ (FREE, just register)\n",
        "2. Run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize collector\n",
        "# IMPORTANT: Get your API key from https://evds2.tcmb.gov.tr/\n",
        "# You can either:\n",
        "# 1. Set it here: EVDS_API_KEY = \"your_key_here\"\n",
        "# 2. Or use .env file (recommended): Add EVDS_API_KEY=your_key_here to .env file\n",
        "\n",
        "# Try to load API key from .env file first\n",
        "from load_env import get_evds_api_key\n",
        "EVDS_API_KEY = get_evds_api_key()\n",
        "\n",
        "# If not in .env, try manual setting\n",
        "if EVDS_API_KEY is None:\n",
        "    EVDS_API_KEY = \"YOUR_API_KEY\"  # ‚ö†Ô∏è Replace with your actual API key!\n",
        "\n",
        "if EVDS_API_KEY is None or EVDS_API_KEY == \"YOUR_API_KEY\":\n",
        "    print(\"‚ö†Ô∏è  Please set your EVDS API key first!\")\n",
        "    print(\"\\nüìã How to get API key:\")\n",
        "    get_evds_api_key_instructions()\n",
        "    print(\"\\nüí° Tip: You can also add it to .env file: EVDS_API_KEY=your_key_here\")\n",
        "    macro_data = pd.DataFrame()  # Initialize as empty to avoid NameError\n",
        "else:\n",
        "    collector = TurkishFinancialDataCollector(\n",
        "        data_dir=data_raw_dir,\n",
        "        evds_api_key=EVDS_API_KEY\n",
        "    )\n",
        "    \n",
        "    # Collect macroeconomic data\n",
        "    print(\"üìä Collecting macroeconomic data from CBRT EVDS...\")\n",
        "    macro_data = collector.collect_cbrt_macroeconomic_data(\n",
        "        start_date=\"01-01-2000\",\n",
        "        end_date=\"31-12-2024\"\n",
        "    )\n",
        "    \n",
        "    if not macro_data.empty:\n",
        "        print(f\"\\n‚úÖ Successfully collected macroeconomic data!\")\n",
        "        print(f\"   Shape: {macro_data.shape}\")\n",
        "        print(f\"   Columns: {macro_data.columns.tolist()}\")\n",
        "        print(f\"   Date range: {macro_data['Date'].min()} to {macro_data['Date'].max()}\")\n",
        "        print(\"\\nFirst few rows:\")\n",
        "        display(macro_data.head(10))\n",
        "        print(\"\\nData info:\")\n",
        "        print(macro_data.info())\n",
        "        print(\"\\nStatistical summary:\")\n",
        "        display(macro_data.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 2: BIST Stock Prices (Yahoo Finance) ‚≠ê\n",
        "\n",
        "**Source:** Yahoo Finance (via yfinance library)\n",
        "\n",
        "**What you'll get:**\n",
        "- Historical daily stock prices (Open, High, Low, Close, Volume)\n",
        "- BIST-100 index data\n",
        "- Individual company stocks\n",
        "- Time-series format (daily data from 2000+)\n",
        "\n",
        "**No API key needed!** This is free and easy to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Collecting BIST-100 Index data...\n",
            "üìä Collecting XU100.IS...\n",
            "   ‚úÖ XU100.IS: 6253 records (2000-01-04 00:00:00+02:00 to 2024-12-30 00:00:00+03:00)\n",
            "\n",
            "‚úÖ Saved stock data to: C:\\Users\\cihan\\turkish_finance_ml\\data\\raw\\bist_stock_prices.csv\n",
            "   Shape: (6253, 9)\n",
            "   Tickers: ['XU100.IS']\n",
            "\n",
            "‚úÖ Successfully collected BIST-100 data!\n",
            "   Shape: (6253, 9)\n",
            "   Date range: 2000-01-04 00:00:00+02:00 to 2024-12-30 00:00:00+03:00\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>Ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-04 00:00:00+02:00</td>\n",
              "      <td>152.087189</td>\n",
              "      <td>176.392068</td>\n",
              "      <td>152.087189</td>\n",
              "      <td>175.121063</td>\n",
              "      <td>5453870000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-05 00:00:00+02:00</td>\n",
              "      <td>175.121063</td>\n",
              "      <td>178.020050</td>\n",
              "      <td>162.376136</td>\n",
              "      <td>169.319107</td>\n",
              "      <td>6672090000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-06 00:00:00+02:00</td>\n",
              "      <td>169.319114</td>\n",
              "      <td>174.606074</td>\n",
              "      <td>160.867148</td>\n",
              "      <td>161.999146</td>\n",
              "      <td>6609500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-07 00:00:00+02:00</td>\n",
              "      <td>161.999142</td>\n",
              "      <td>163.055136</td>\n",
              "      <td>156.234173</td>\n",
              "      <td>158.373154</td>\n",
              "      <td>2544440000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-11 00:00:00+02:00</td>\n",
              "      <td>158.373150</td>\n",
              "      <td>163.882124</td>\n",
              "      <td>152.931193</td>\n",
              "      <td>163.473129</td>\n",
              "      <td>5361840000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2000-01-12 00:00:00+02:00</td>\n",
              "      <td>163.473130</td>\n",
              "      <td>173.041087</td>\n",
              "      <td>163.473130</td>\n",
              "      <td>169.335098</td>\n",
              "      <td>5969170000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2000-01-13 00:00:00+02:00</td>\n",
              "      <td>169.335101</td>\n",
              "      <td>182.567026</td>\n",
              "      <td>169.335101</td>\n",
              "      <td>181.381042</td>\n",
              "      <td>7364170000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2000-01-14 00:00:00+02:00</td>\n",
              "      <td>181.381048</td>\n",
              "      <td>193.319980</td>\n",
              "      <td>181.381048</td>\n",
              "      <td>191.101990</td>\n",
              "      <td>6785520000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2000-01-17 00:00:00+02:00</td>\n",
              "      <td>191.101986</td>\n",
              "      <td>206.177910</td>\n",
              "      <td>183.012032</td>\n",
              "      <td>184.582016</td>\n",
              "      <td>7324420000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2000-01-18 00:00:00+02:00</td>\n",
              "      <td>184.582014</td>\n",
              "      <td>195.771957</td>\n",
              "      <td>181.824033</td>\n",
              "      <td>195.771957</td>\n",
              "      <td>5954870000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>XU100.IS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Date        Open        High         Low       Close  \\\n",
              "0 2000-01-04 00:00:00+02:00  152.087189  176.392068  152.087189  175.121063   \n",
              "1 2000-01-05 00:00:00+02:00  175.121063  178.020050  162.376136  169.319107   \n",
              "2 2000-01-06 00:00:00+02:00  169.319114  174.606074  160.867148  161.999146   \n",
              "3 2000-01-07 00:00:00+02:00  161.999142  163.055136  156.234173  158.373154   \n",
              "4 2000-01-11 00:00:00+02:00  158.373150  163.882124  152.931193  163.473129   \n",
              "5 2000-01-12 00:00:00+02:00  163.473130  173.041087  163.473130  169.335098   \n",
              "6 2000-01-13 00:00:00+02:00  169.335101  182.567026  169.335101  181.381042   \n",
              "7 2000-01-14 00:00:00+02:00  181.381048  193.319980  181.381048  191.101990   \n",
              "8 2000-01-17 00:00:00+02:00  191.101986  206.177910  183.012032  184.582016   \n",
              "9 2000-01-18 00:00:00+02:00  184.582014  195.771957  181.824033  195.771957   \n",
              "\n",
              "       Volume  Dividends  Stock Splits    Ticker  \n",
              "0  5453870000        0.0           0.0  XU100.IS  \n",
              "1  6672090000        0.0           0.0  XU100.IS  \n",
              "2  6609500000        0.0           0.0  XU100.IS  \n",
              "3  2544440000        0.0           0.0  XU100.IS  \n",
              "4  5361840000        0.0           0.0  XU100.IS  \n",
              "5  5969170000        0.0           0.0  XU100.IS  \n",
              "6  7364170000        0.0           0.0  XU100.IS  \n",
              "7  6785520000        0.0           0.0  XU100.IS  \n",
              "8  7324420000        0.0           0.0  XU100.IS  \n",
              "9  5954870000        0.0           0.0  XU100.IS  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìä Collecting data for major BIST-100 companies...\n",
            "============================================================\n",
            "üìä Collecting AKBNK.IS...\n",
            "   ‚úÖ AKBNK.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting GARAN.IS...\n",
            "   ‚úÖ GARAN.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting THYAO.IS...\n",
            "   ‚úÖ THYAO.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting TUPRS.IS...\n",
            "   ‚úÖ TUPRS.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting SAHOL.IS...\n",
            "   ‚úÖ SAHOL.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting BIMAS.IS...\n",
            "   ‚úÖ BIMAS.IS: 5252 records (2005-07-22 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting ARCLK.IS...\n",
            "   ‚úÖ ARCLK.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting KOZAL.IS...\n",
            "   ‚úÖ KOZAL.IS: 4091 records (2010-02-12 00:00:00+02:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting SASA.IS...\n",
            "   ‚úÖ SASA.IS: 6610 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "üìä Collecting PETKM.IS...\n",
            "   ‚úÖ PETKM.IS: 6609 records (2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00)\n",
            "\n",
            "‚úÖ Saved stock data to: C:\\Users\\cihan\\turkish_finance_ml\\data\\raw\\bist_stock_prices.csv\n",
            "   Shape: (62216, 9)\n",
            "   Tickers: ['AKBNK.IS' 'GARAN.IS' 'THYAO.IS' 'TUPRS.IS' 'SAHOL.IS' 'BIMAS.IS'\n",
            " 'ARCLK.IS' 'KOZAL.IS' 'SASA.IS' 'PETKM.IS']\n",
            "\n",
            "‚úÖ Successfully collected stock data for 10 companies!\n",
            "   Shape: (62216, 9)\n",
            "   Tickers: ['AKBNK.IS' 'GARAN.IS' 'THYAO.IS' 'TUPRS.IS' 'SAHOL.IS' 'BIMAS.IS'\n",
            " 'ARCLK.IS' 'KOZAL.IS' 'SASA.IS' 'PETKM.IS']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>Ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-05-10 00:00:00+03:00</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>-123009.857107</td>\n",
              "      <td>-115158.171109</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>1284067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-05-11 00:00:00+03:00</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>-120392.619291</td>\n",
              "      <td>-112540.933293</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>608846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-05-12 00:00:00+03:00</td>\n",
              "      <td>-120392.601563</td>\n",
              "      <td>-123009.838993</td>\n",
              "      <td>-115158.154152</td>\n",
              "      <td>-120392.601562</td>\n",
              "      <td>2283592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-05-15 00:00:00+03:00</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>-120392.619291</td>\n",
              "      <td>-115158.171109</td>\n",
              "      <td>-117775.390625</td>\n",
              "      <td>122956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-05-16 00:00:00+03:00</td>\n",
              "      <td>-115158.164062</td>\n",
              "      <td>-117775.383418</td>\n",
              "      <td>-112540.926406</td>\n",
              "      <td>-115158.164062</td>\n",
              "      <td>1331524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2000-05-17 00:00:00+03:00</td>\n",
              "      <td>-115158.164062</td>\n",
              "      <td>-117775.383418</td>\n",
              "      <td>-109923.697900</td>\n",
              "      <td>-115158.164062</td>\n",
              "      <td>1062260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2000-05-18 00:00:00+03:00</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>-109923.706614</td>\n",
              "      <td>-102072.002173</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>1716238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2000-05-19 00:00:00+03:00</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>-107306.468750</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2000-05-22 00:00:00+03:00</td>\n",
              "      <td>-102595.460938</td>\n",
              "      <td>-104689.247722</td>\n",
              "      <td>-99454.780761</td>\n",
              "      <td>-102595.460938</td>\n",
              "      <td>1728168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2000-05-23 00:00:00+03:00</td>\n",
              "      <td>-102595.460938</td>\n",
              "      <td>-104689.247722</td>\n",
              "      <td>-99454.780761</td>\n",
              "      <td>-102595.460938</td>\n",
              "      <td>1728168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AKBNK.IS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Date           Open           High            Low  \\\n",
              "0 2000-05-10 00:00:00+03:00 -117775.390625 -123009.857107 -115158.171109   \n",
              "1 2000-05-11 00:00:00+03:00 -117775.390625 -120392.619291 -112540.933293   \n",
              "2 2000-05-12 00:00:00+03:00 -120392.601563 -123009.838993 -115158.154152   \n",
              "3 2000-05-15 00:00:00+03:00 -117775.390625 -120392.619291 -115158.171109   \n",
              "4 2000-05-16 00:00:00+03:00 -115158.164062 -117775.383418 -112540.926406   \n",
              "5 2000-05-17 00:00:00+03:00 -115158.164062 -117775.383418 -109923.697900   \n",
              "6 2000-05-18 00:00:00+03:00 -107306.468750 -109923.706614 -102072.002173   \n",
              "7 2000-05-19 00:00:00+03:00 -107306.468750 -107306.468750 -107306.468750   \n",
              "8 2000-05-22 00:00:00+03:00 -102595.460938 -104689.247722  -99454.780761   \n",
              "9 2000-05-23 00:00:00+03:00 -102595.460938 -104689.247722  -99454.780761   \n",
              "\n",
              "           Close   Volume  Dividends  Stock Splits    Ticker  \n",
              "0 -117775.390625  1284067        0.0           0.0  AKBNK.IS  \n",
              "1 -117775.390625   608846        0.0           0.0  AKBNK.IS  \n",
              "2 -120392.601562  2283592        0.0           0.0  AKBNK.IS  \n",
              "3 -117775.390625   122956        0.0           0.0  AKBNK.IS  \n",
              "4 -115158.164062  1331524        0.0           0.0  AKBNK.IS  \n",
              "5 -115158.164062  1062260        0.0           0.0  AKBNK.IS  \n",
              "6 -107306.468750  1716238        0.0           0.0  AKBNK.IS  \n",
              "7 -107306.468750        0        0.0           0.0  AKBNK.IS  \n",
              "8 -102595.460938  1728168        0.0           0.0  AKBNK.IS  \n",
              "9 -102595.460938  1728168        0.0           0.0  AKBNK.IS  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize collector (no API key needed for stock data)\n",
        "collector_stocks = TurkishFinancialDataCollector(data_dir=data_raw_dir)\n",
        "\n",
        "# Option A: Collect BIST-100 index only\n",
        "print(\"üìä Collecting BIST-100 Index data...\")\n",
        "bist_index = collector_stocks.collect_bist_stock_data(\n",
        "    tickers=['XU100.IS'],  # BIST-100 index\n",
        "    start_date=\"2000-01-01\",\n",
        "    end_date=\"2024-12-31\"\n",
        ")\n",
        "\n",
        "if not bist_index.empty:\n",
        "    print(f\"\\n‚úÖ Successfully collected BIST-100 data!\")\n",
        "    print(f\"   Shape: {bist_index.shape}\")\n",
        "    print(f\"   Date range: {bist_index['Date'].min()} to {bist_index['Date'].max()}\")\n",
        "    display(bist_index.head(10))\n",
        "\n",
        "# Option B: Collect multiple major BIST companies\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Collecting data for major BIST-100 companies...\")\n",
        "print(\"=\"*60)\n",
        "major_stocks = collector_stocks.collect_bist_100_companies()\n",
        "\n",
        "if not major_stocks.empty:\n",
        "    print(f\"\\n‚úÖ Successfully collected stock data for {major_stocks['Ticker'].nunique()} companies!\")\n",
        "    print(f\"   Shape: {major_stocks.shape}\")\n",
        "    print(f\"   Tickers: {major_stocks['Ticker'].unique()}\")\n",
        "    display(major_stocks.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 3: Combine Stock and Macro Data\n",
        "\n",
        "Merge stock prices with macroeconomic indicators for comprehensive analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  Macro data file not found. Please run the macro collection cell first.\n",
            "‚ö†Ô∏è  Macro data not available. Set your EVDS API key and run macro collection cell first.\n",
            "   Or ensure cbrt_macroeconomic_data.csv exists in data/raw/ folder\n"
          ]
        }
      ],
      "source": [
        "# Combine stock and macro data\n",
        "# Note: Stock data is daily, macro data is monthly\n",
        "# We'll forward-fill macro data to match daily frequency\n",
        "\n",
        "# Check if variables exist, if not try loading from files\n",
        "try:\n",
        "    _ = bist_index\n",
        "    if bist_index.empty:\n",
        "        bist_index = pd.DataFrame()\n",
        "except NameError:\n",
        "    bist_index = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "    _ = macro_data\n",
        "    if macro_data.empty:\n",
        "        macro_data = pd.DataFrame()\n",
        "except NameError:\n",
        "    macro_data = pd.DataFrame()\n",
        "\n",
        "# Try loading from saved files if variables are empty\n",
        "if bist_index.empty:\n",
        "    stock_file = data_raw_dir / \"bist_stock_prices.csv\"\n",
        "    if stock_file.exists():\n",
        "        df_stock = pd.read_csv(stock_file)\n",
        "        # Filter for BIST-100 index if available\n",
        "        if 'Ticker' in df_stock.columns:\n",
        "            bist_index = df_stock[df_stock['Ticker'] == 'XU100.IS'].copy()\n",
        "        else:\n",
        "            bist_index = df_stock.copy()\n",
        "        print(\"‚úÖ Loaded stock data from saved file\")\n",
        "\n",
        "if macro_data.empty:\n",
        "    macro_file = data_raw_dir / \"cbrt_macroeconomic_data.csv\"\n",
        "    if macro_file.exists():\n",
        "        macro_data = pd.read_csv(macro_file)\n",
        "        macro_data['Date'] = pd.to_datetime(macro_data['Date'])\n",
        "        print(\"‚úÖ Loaded macro data from saved file\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Macro data file not found. Please run the macro collection cell first.\")\n",
        "\n",
        "# Now combine the data\n",
        "if not bist_index.empty and not macro_data.empty:\n",
        "    # Prepare stock data\n",
        "    stock_daily = bist_index[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "    stock_daily['Date'] = pd.to_datetime(stock_daily['Date'])\n",
        "    stock_daily = stock_daily.sort_values('Date').reset_index(drop=True)\n",
        "    \n",
        "    # Prepare macro data\n",
        "    macro_monthly = macro_data.copy()\n",
        "    macro_monthly['Date'] = pd.to_datetime(macro_monthly['Date'])\n",
        "    macro_monthly = macro_monthly.sort_values('Date').reset_index(drop=True)\n",
        "    \n",
        "    # Merge: forward-fill monthly macro data to daily stock data\n",
        "    combined = stock_daily.merge(\n",
        "        macro_monthly,\n",
        "        on='Date',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Forward-fill macro indicators (monthly values fill forward to daily)\n",
        "    macro_cols = [col for col in macro_monthly.columns if col != 'Date']\n",
        "    combined[macro_cols] = combined[macro_cols].fillna(method='ffill')\n",
        "    \n",
        "    # Save combined dataset\n",
        "    output_file = data_raw_dir / \"combined_stock_macro_data.csv\"\n",
        "    combined.to_csv(output_file, index=False)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Combined dataset created!\")\n",
        "    print(f\"   Shape: {combined.shape}\")\n",
        "    print(f\"   Saved to: {output_file}\")\n",
        "    print(f\"   Date range: {combined['Date'].min()} to {combined['Date'].max()}\")\n",
        "    print(f\"\\nColumns: {combined.columns.tolist()}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    display(combined.head(10))\n",
        "    print(\"\\nMissing values:\")\n",
        "    print(combined.isnull().sum())\n",
        "    \n",
        "elif bist_index.empty:\n",
        "    print(\"‚ö†Ô∏è  Stock data not available. Run the stock collection cell first.\")\n",
        "elif macro_data.empty:\n",
        "    print(\"‚ö†Ô∏è  Macro data not available. Set your EVDS API key and run macro collection cell first.\")\n",
        "    print(\"   Or ensure cbrt_macroeconomic_data.csv exists in data/raw/ folder\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Both datasets needed for combination.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Data Inspection\n",
        "\n",
        "Check the collected datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA COLLECTION SUMMARY\n",
            "============================================================\n",
            "\n",
            "‚úÖ Stock Prices Data:\n",
            "   File: C:\\Users\\cihan\\turkish_finance_ml\\data\\raw\\bist_stock_prices.csv\n",
            "   Shape: (62216, 9)\n",
            "   Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Ticker']\n",
            "   Date range: 2000-05-10 00:00:00+03:00 to 2026-01-16 00:00:00+03:00\n",
            "   Tickers: ['AKBNK.IS' 'GARAN.IS' 'THYAO.IS' 'TUPRS.IS' 'SAHOL.IS' 'BIMAS.IS'\n",
            " 'ARCLK.IS' 'KOZAL.IS' 'SASA.IS' 'PETKM.IS']\n",
            "\n",
            "============================================================\n",
            "Total datasets collected: 1\n",
            "============================================================\n",
            "\n",
            "‚úÖ Data collection complete! Ready for EDA.\n",
            "   Next step: Run 02_eda_exploration.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Check all collected datasets\n",
        "print(\"=\"*60)\n",
        "print(\"DATA COLLECTION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "# Check for macro data\n",
        "macro_file = data_raw_dir / \"cbrt_macroeconomic_data.csv\"\n",
        "if macro_file.exists():\n",
        "    df_macro = pd.read_csv(macro_file)\n",
        "    datasets['Macroeconomic Data'] = df_macro\n",
        "    print(f\"\\n‚úÖ Macroeconomic Data:\")\n",
        "    print(f\"   File: {macro_file}\")\n",
        "    print(f\"   Shape: {df_macro.shape}\")\n",
        "    print(f\"   Columns: {df_macro.columns.tolist()}\")\n",
        "    print(f\"   Date range: {df_macro['Date'].min()} to {df_macro['Date'].max()}\")\n",
        "\n",
        "# Check for stock data\n",
        "stock_file = data_raw_dir / \"bist_stock_prices.csv\"\n",
        "if stock_file.exists():\n",
        "    df_stock = pd.read_csv(stock_file)\n",
        "    datasets['Stock Prices'] = df_stock\n",
        "    print(f\"\\n‚úÖ Stock Prices Data:\")\n",
        "    print(f\"   File: {stock_file}\")\n",
        "    print(f\"   Shape: {df_stock.shape}\")\n",
        "    print(f\"   Columns: {df_stock.columns.tolist()}\")\n",
        "    if 'Date' in df_stock.columns:\n",
        "        print(f\"   Date range: {df_stock['Date'].min()} to {df_stock['Date'].max()}\")\n",
        "    if 'Ticker' in df_stock.columns:\n",
        "        print(f\"   Tickers: {df_stock['Ticker'].unique()}\")\n",
        "\n",
        "# Check for combined data\n",
        "combined_file = data_raw_dir / \"combined_stock_macro_data.csv\"\n",
        "if combined_file.exists():\n",
        "    df_combined = pd.read_csv(combined_file)\n",
        "    datasets['Combined Data'] = df_combined\n",
        "    print(f\"\\n‚úÖ Combined Data:\")\n",
        "    print(f\"   File: {combined_file}\")\n",
        "    print(f\"   Shape: {df_combined.shape}\")\n",
        "    print(f\"   Columns: {df_combined.columns.tolist()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"Total datasets collected: {len(datasets)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if len(datasets) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  No datasets found. Please run the collection cells above.\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ Data collection complete! Ready for EDA.\")\n",
        "    print(\"   Next step: Run 02_eda_exploration.ipynb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Data Sources (Optional)\n",
        "\n",
        "### Kaggle Datasets\n",
        "If you want pre-processed datasets, consider downloading from Kaggle:\n",
        "\n",
        "1. **Borsa Istanbul Stock Exchange Dataset**\n",
        "   - Link: https://www.kaggle.com/datasets/gokhankesler/borsa-istanbul-turkish-stock-exchange-dataset\n",
        "   - Download and place in `data/raw/` folder\n",
        "\n",
        "2. **BIST100 Turkish Stock Market**\n",
        "   - Link: https://www.kaggle.com/datasets/hakanetin/bist100turkishstaockmarketturkhissefiyatlar\n",
        "   - Download and place in `data/raw/` folder\n",
        "\n",
        "### Financial Ratios Dataset (Zenodo)\n",
        "- Link: https://zenodo.org/records/15551015\n",
        "- Download and place in `data/raw/` folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "‚úÖ DATA COLLECTION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "üìã Next Steps:\n",
            "   1. Review collected datasets above\n",
            "   2. Check data quality and completeness\n",
            "   3. Proceed to: 02_eda_exploration.ipynb\n",
            "\n",
            "üí° Tip: All data is saved in data/raw/ folder for reproducibility\n"
          ]
        }
      ],
      "source": [
        "# Load any additional datasets you downloaded manually\n",
        "# Example:\n",
        "# kaggle_data = pd.read_csv(data_raw_dir / \"kaggle_dataset.csv\")\n",
        "# print(f\"Kaggle dataset shape: {kaggle_data.shape}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ DATA COLLECTION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìã Next Steps:\")\n",
        "print(\"   1. Review collected datasets above\")\n",
        "print(\"   2. Check data quality and completeness\")\n",
        "print(\"   3. Proceed to: 02_eda_exploration.ipynb\")\n",
        "print(\"\\nüí° Tip: All data is saved in data/raw/ folder for reproducibility\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
